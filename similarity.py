"""
Module de recherche par similarit√© de jobs
Bas√© sur la similarit√© cosinus et embeddings
"""

import joblib
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import Dict, List, Optional
from pathlib import Path


class JobSimilaritySearch:
    """
    Recherche de jobs similaires par comp√©tences
    Utilise XGBoost pour la classification + similarit√© cosinus
    """
    
    # Seuils (identiques √† ton rech_sim4.py)
    CONFIDENCE_THRESHOLD = 0.35  # Seuil de confiance du mod√®le
    SIMILARITY_THRESHOLD = 0.30  # Seuil de similarit√© minimale
    MODERATE_CONFIDENCE = 0.50   # Seuil de confiance mod√©r√©e
    MODERATE_SIMILARITY = 0.40   # Seuil de similarit√© mod√©r√©e
    
    def __init__(self, models_dir= "models", data_dir = "data"):
        """
        Initialise le syst√®me de recherche
        
        Args:
            models_dir: R√©pertoire contenant les mod√®les
            data_dir: R√©pertoire contenant les donn√©es
        """
        self.models_dir = Path(models_dir)
        self.data_dir = Path(data_dir)
        
        self.xgboost_model = None
        self.label_encoder = None
        self.sentence_model = None
        self.df = None
        self.jobs_embeddings = None
        
        self._load_resources()
    
    def _load_resources(self):
        """Charge tous les mod√®les et donn√©es n√©cessaires"""
        try:
            # 1. Mod√®le XGBoost
            xgb_path = self.models_dir / "model_xgboost.pkl"
            self.xgboost_model = joblib.load(xgb_path)
            print(f"‚úì XGBoost charg√© depuis {xgb_path}")
            
            # 2. Label Encoder
            le_path = self.models_dir / "label_encoder.pkl"
            self.label_encoder = joblib.load(le_path)
            print(f"‚úì Label encoder charg√© depuis {le_path}")
            
            # 3. Sentence Transformer
            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
            print("‚úì Sentence Transformer charg√©")
            
            # 4. Base de donn√©es des jobs
            csv_path = self.data_dir / "BD_nettoy√©e.csv"
            self.df = pd.read_csv(csv_path)
            print(f"‚úì Base de donn√©es charg√©e: {len(self.df)} jobs")
            
            # 5. Embeddings des jobs
            embeddings_path = self.models_dir / "job_embeddings_all.npy"
            self.jobs_embeddings = np.load(embeddings_path)
            print(f"‚úì Embeddings charg√©s: {self.jobs_embeddings.shape}")
            
        except Exception as e:
            raise RuntimeError(f"Erreur lors du chargement des ressources: {e}")
    
    def encode_skills(self, skills_text) :
        """
        Encode le texte de comp√©tences en embedding
        
        Args:
            skills_text: Texte des comp√©tences
        
        Returns:
            Embedding normalis√©
        """
        embedding = self.sentence_model.encode(
            [skills_text], 
            normalize_embeddings=True
        )
        return embedding
    
    def recommend_jobs( self,  skills_text,  k = 5, include_scores = True
) :
        """
        Recommande des jobs bas√©s sur les comp√©tences
        
        Args:
            skills_text: Texte des comp√©tences
            k: Nombre de jobs √† recommander
            include_scores: Inclure les scores de similarit√©
        
        Returns:
            Dictionnaire contenant:
                - success: True si recommandations trouv√©es
                - predicted_class: Classe pr√©dite
                - confidence: Confiance de la pr√©diction
                - similarity_max: Similarit√© maximale
                - similarity_avg: Similarit√© moyenne
                - recommendations: Liste des jobs recommand√©s
                - warnings: Liste d'avertissements
                - rejection_reason: Raison du rejet si applicable
        """
        
        # Encodage des comp√©tences
        skills_embedding = self.encode_skills(skills_text)
        
        # ====================================================================
        # √âTAPE 1 : PR√âDICTION DE LA CLASSE
        # ====================================================================
        probabilities = self.xgboost_model.predict_proba(skills_embedding)[0]
        max_proba = probabilities.max()
        predicted_class_num = self.xgboost_model.predict(skills_embedding)[0]
        predicted_class = self.label_encoder.inverse_transform([predicted_class_num])[0]
        
        # Top 3 des classes probables
        top3_indices = probabilities.argsort()[::-1][:3]
        top3_predictions = []
        for idx in top3_indices:
            top3_predictions.append({
                "class": self.label_encoder.classes_[idx],
                "probability": float(probabilities[idx])
            })
        
        # ====================================================================
        # S√âCURIT√â 1 : V√©rification de la confiance
        # ====================================================================
        if max_proba < self.CONFIDENCE_THRESHOLD:
            # Calcul de l'√©cart entre les 2 meilleures classes
            top2_probas = probabilities[probabilities.argsort()[::-1][:2]]
            gap = top2_probas[0] - top2_probas[1]
            
            return {
                "success": False,
                "predicted_class": predicted_class,
                "confidence": float(max_proba),
                "top3_predictions": top3_predictions,
                "rejection_reason": "confidence_too_low",
                "message": (
                    f"Confiance insuffisante ({max_proba:.2%}). "
                    f"Le mod√®le h√©site entre plusieurs classes. "
                    f"√âcart entre les 2 meilleures: {gap:.2%}"
                ),
                "suggestions": [
                    "Ajoutez des comp√©tences plus sp√©cifiques",
                    "Essayez des termes techniques (Python, SQL, Machine Learning)",
                    "V√©rifiez l'orthographe"
                ]
            }
        
        # ====================================================================
        # √âTAPE 2 : RECHERCHE DES JOBS SIMILAIRES
        # ====================================================================
        # Filtrer les jobs de la classe pr√©dite
        indices = self.df.index[self.df['title'] == predicted_class.lower().strip()].to_numpy()
        
        if len(indices) == 0:
            return {
                "success": False,
                "predicted_class": predicted_class,
                "confidence": float(max_proba),
                "rejection_reason": "no_jobs_in_class",
                "message": f"Aucun job trouv√© pour la classe: {predicted_class}"
            }
        
        # Calcul des similarit√©s
        skill_embedding_2d = skills_embedding.reshape(1, -1)
        similarities = cosine_similarity(
            skill_embedding_2d, 
            self.jobs_embeddings[indices]
        )[0]
        
        max_similarity = similarities.max()
        avg_similarity = similarities.mean()
        
        # ====================================================================
        # S√âCURIT√â 2 : V√©rification de la similarit√©
        # ====================================================================
        if max_similarity < self.SIMILARITY_THRESHOLD:
            return {
                "success": False,
                "predicted_class": predicted_class,
                "confidence": float(max_proba),
                "similarity_max": float(max_similarity),
                "similarity_avg": float(avg_similarity),
                "top3_predictions": top3_predictions,
                "rejection_reason": "similarity_too_low",
                "message": (
                    f"Similarit√© trop faible ({max_similarity:.2%}). "
                    f"M√™me dans la classe '{predicted_class}', aucun job "
                    f"ne correspond vraiment aux comp√©tences saisies."
                ),
                "suggestions": [
                    "Utilisez des comp√©tences li√©es √† la data/tech",
                    "Exemples: Python, SQL, Tableau, Machine Learning"
                ]
            }
        
        # ====================================================================
        # √âTAPE 3 : G√âN√âRATION DES AVERTISSEMENTS
        # ====================================================================
        warnings = []
        
        if self.CONFIDENCE_THRESHOLD <= max_proba < self.MODERATE_CONFIDENCE:
            warnings.append({
                "type": "moderate_confidence",
                "message": f"Confiance mod√©r√©e ({max_proba:.2%}). Les r√©sultats peuvent √™tre moins pr√©cis."
            })
        
        if self.SIMILARITY_THRESHOLD <= max_similarity < self.MODERATE_SIMILARITY:
            warnings.append({
                "type": "moderate_similarity",
                "message": f"Similarit√© mod√©r√©e ({max_similarity:.2%}). Les jobs propos√©s correspondent partiellement."
            })
        
        # ====================================================================
        # √âTAPE 4 : CR√âATION DES RECOMMANDATIONS
        # ====================================================================
        # Top-k indices tri√©s par similarit√©
        top_k_indices_local = similarities.argsort()[::-1][:k]
        top_k_indices = indices[top_k_indices_local]
        top_k_similarities = similarities[top_k_indices_local]
        
        # R√©cup√©ration des jobs
        recommendations = []
        for idx, (job_idx, sim_score) in enumerate(zip(top_k_indices, top_k_similarities), 1):
            job = self.df.iloc[job_idx]
            
            rec = {
                "rank": idx,
                "title": job['title'],
                "company": job['company'],
                "location": job['location'],
                "skills": eval(job['skills']) if isinstance(job['skills'], str) else job['skills']
            }
            
            if include_scores:
                rec["similarity_score"] = float(sim_score)
            
            recommendations.append(rec)
        
        # ====================================================================
        # √âTAPE 5 : R√âSULTAT FINAL
        # ====================================================================
        result = {
            "success": True,
            "predicted_class": predicted_class,
            "confidence": float(max_proba),
            "top3_predictions": top3_predictions,
            "similarity_max": float(max_similarity),
            "similarity_avg": float(avg_similarity),
            "num_jobs_in_class": len(indices),
            "recommendations": recommendations,
            "warnings": warnings
        }
        
        # √âvaluation globale de la qualit√©
        if avg_similarity >= 0.50:
            result["quality"] = "excellent"
        elif avg_similarity >= 0.40:
            result["quality"] = "good"
        else:
            result["quality"] = "moderate"
        
        return result
    
    def get_job_details(self, job_index) :
        """
        R√©cup√®re les d√©tails d'un job par son index
        
        Args:
            job_index: Index du job dans la base de donn√©es
        
        Returns:
            Dictionnaire avec les d√©tails du job ou None
        """
        if job_index < 0 or job_index >= len(self.df):
            return None
        
        job = self.df.iloc[job_index]
        return {
            "title": job['title'],
            "company": job['company'],
            "location": job['location'],
            "skills": eval(job['skills']) if isinstance(job['skills'], str) else job['skills']
        }
    
    def get_stats(self):
        """
        Retourne des statistiques sur la base de donn√©es
        
        Returns:
            Statistiques g√©n√©rales
        """
        return {
            "total_jobs": len(self.df),
            "available_classes": self.label_encoder.classes_.tolist(),
            "jobs_per_class": self.df['title'].value_counts().to_dict()
        }


# ============================================================================
# EXEMPLE D'UTILISATION
# ============================================================================
if __name__ == "__main__":
    # Initialisation
    search_engine = JobSimilaritySearch(models_dir="models", data_dir="data")
    
    # Statistiques
    print("\n" + "="*70)
    print(" STATISTIQUES DE LA BASE")
    print("="*70)
    stats = search_engine.get_stats()
    print(f"Total de jobs: {stats['total_jobs']}")
    print(f"Classes disponibles: {', '.join(stats['available_classes'])}")
    
    # Test de recherche
    print("\n" + "="*70)
    print(" TEST DE RECHERCHE")
    print("="*70)
    
    test_skills = "Python SQL Machine Learning pandas scikit-learn"
    print(f"\n Comp√©tences: {test_skills}")
    
    result = search_engine.recommend_jobs(test_skills, k=5, include_scores=True)
    
    if result["success"]:
        print(f"\n SUCC√àS")
        print(f" Classe pr√©dite: {result['predicted_class']}")
        print(f" Confiance: {result['confidence']:.2%}")
        print(f" Similarit√© max: {result['similarity_max']:.2%}")
        print(f" Similarit√© moyenne: {result['similarity_avg']:.2%}")
        print(f" Qualit√©: {result['quality']}")
        
        # Avertissements
        if result["warnings"]:
            print(f"\n  AVERTISSEMENTS:")
            for warning in result["warnings"]:
                print(f"   ‚Ä¢ {warning['message']}")
        
        # Recommandations
        print(f"\n TOP {len(result['recommendations'])} RECOMMANDATIONS:")
        for rec in result["recommendations"]:
            emoji = "ü•á" if rec['rank'] == 1 else "ü•à" if rec['rank'] == 2 else "ü•â" if rec['rank'] == 3 else "  "
            print(f"\n{emoji} #{rec['rank']} - {rec['title']}")
            print(f"    {rec['company']}")
            print(f"    {rec['location']}")
            print(f"    Similarit√©: {rec['similarity_score']:.2%}")
            print(f"    Comp√©tences: {', '.join(rec['skills'][:5])}...")
    
    else:
        print(f"\n √âCHEC")
        print(f"Raison: {result['rejection_reason']}")
        print(f"Message: {result['message']}")
        
        if result.get("suggestions"):
            print(f"\n SUGGESTIONS:")
            for suggestion in result["suggestions"]:
                print(f"   ‚Ä¢ {suggestion}")
    
    print("\n" + "="*70)
